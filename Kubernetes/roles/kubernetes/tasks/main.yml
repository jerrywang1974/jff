# vi: et ts=2 sts=2 sw=2 ai
---

- name: enable bridge-nf-call-iptables
  copy: src=99-enable-bridge-nf-call-iptables.conf dest=/etc/sysctl.d/99-enable-bridge-nf-call-iptables.conf
        group=root owner=root mode=0644
  register: sysctl_bridge_nf_call_iptables_changed
  tags: kubernetes

- name: disable rp_filter
  copy: src=99-disable-rp_filter.conf dest=/etc/sysctl.d/99-disable-rp_filter.conf
        group=root owner=root mode=0644
  register: sysctl_rp_filter_changed
  when: kubernetes_disable_rp_filter | bool
  tags: kubernetes

- name: restart service procps if necessary
  service: name=procps state=restarted
  when: (sysctl_bridge_nf_call_iptables_changed | changed) or (sysctl_rp_filter_changed | changed)
  tags: kubernetes

- name: install kubernetes
  apt: name={{ item }} state=present
  with_items:
    - kubeadm={{ kubeadm_version }}
    - kubectl={{ kubectl_version }}
    - kubelet={{ kubelet_version }}
    - kubernetes-cni={{ kubernetes_cni_version }}
  tags: kubernetes

- name: install /etc/network/if-up.d/kubernetes-cluster-ip-route
  template: src=kubernetes-cluster-ip-route.j2
            dest=/etc/network/if-up.d/kubernetes-cluster-ip-route
            group=root owner=root mode=0755
  register: if_up_script_installed
  tags: kubernetes

- name: install /etc/network/if-down.d/kubernetes-cluster-ip-route
  template: src=kubernetes-cluster-ip-route.j2
            dest=/etc/network/if-down.d/kubernetes-cluster-ip-route
            group=root owner=root mode=0755
  register: if_down_script_installed
  tags: kubernetes

- name: add route for kubernetes cluster ip range if necessary
  shell: ip route del to {{ kubernetes_service_cidr }}; ip route add to {{ kubernetes_service_cidr }} dev {{ primary_internal_iface }}
  when: if_up_script_installed | changed or if_down_script_installed | changed
  tags: kubernetes

- name: override /etc/systemd/system/kubelet.service.d/10-kubeadm.conf with 60-kubeadm-override.conf
  template: src=60-kubeadm-override.conf.j2
            dest=/etc/systemd/system/kubelet.service.d/60-kubeadm-override.conf
            group=root owner=root mode=0640
  register: kubeadm_conf_overridden
  tags: kubernetes

- name: reload systemd if necessary
  command: systemctl daemon-reload
  when: kubeadm_conf_overridden | changed
  tags: kubernetes

- name: restart kubelet if necessary
  service: name=kubelet state=restarted
  when: kubeadm_conf_overridden | changed
  tags: kubernetes

- name: start kubelet
  service: name=kubelet state=started enabled=yes
  tags: kubernetes

- name: make sure /etc/kubernetes/pki/ exist
  file: path=/etc/kubernetes/pki state=directory recurse=yes
        group=root owner=root mode=0755
  tags: kubernetes

- name: setup /etc/kubernetes/audit-policy.yaml
  copy: src=audit-policy.yaml dest=/etc/kubernetes/audit-policy.yaml
        group=root owner=root mode=0644
  tags: kubernetes

# XXX: kubeadm-1.8.x doesn't support customization of volumes and
# volumeMounts for kube-apiserver yet, so we have to put audit-policy.yaml
# into /etc/kubernetes/pki which is a predefined volume & volumeMount
# in /etc/kubernetes/manifests/kube-apiserver.yaml.
- name: setup /etc/kubernetes/pki/audit-policy.yaml
  copy: src=audit-policy.yaml dest=/etc/kubernetes/pki/audit-policy.yaml
        group=root owner=root mode=0644
  tags: kubernetes

- name: setup /etc/kubernetes/kubeadm-master.conf
  template: src=kubeadm-master.conf.j2
            dest=/etc/kubernetes/kubeadm-master.conf
            group=root owner=root mode=0600
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: initialize Kubernetes master
  command: creates=/etc/kubernetes/kubelet.conf
           kubeadm init --config /etc/kubernetes/kubeadm-master.conf {{ kubeadm_extra_args }}
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: obtain discovery token ca cert hash
  shell: >-
         openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt |
         openssl rsa -pubin -outform der 2>/dev/null |
         openssl dgst -sha256 -hex |
         sed 's/^.* //'
  when: inventory_hostname != groups['kubernetes'][0]
  delegate_to: "{{ groups['kubernetes'][0] }}"
  register: discovery_token_ca_cert_hash_cmd
  tags: kubernetes

# kubectl get pod -n kube-system -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,QOS:.status.qosClass,START:.status.startTime,NODE:.spec.nodeName
- name: change kube-proxy QoS class from BestEffort to Guaranteed
  command: >-
           kubectl --kubeconfig=/etc/kubernetes/admin.conf patch
           daemonset kube-proxy -n kube-system -p
           '{"spec": {"template": {"spec": {"containers": [{
             "name": "kube-proxy",
             "resources": {
               "requests": {
                 "cpu": "20m",
                 "memory": "50Mi"
               },
               "limits": {
                 "cpu": "20m",
                 "memory": "50Mi"
               }
             }
           }]}}}}' --record
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: install /etc/kubernetes/kube-flannel.yml
  template: src=kube-flannel.yml.j2 dest=/etc/kubernetes/kube-flannel.yml
            group=root owner=root mode=0644
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: install Flannel
  command: kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system apply -f /etc/kubernetes/kube-flannel.yml
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

# XXX: Because kubeadm doesn't properly sort apiserver's arguments, we can't
# reliably patch on kube-apiserver.yaml.
- name: adjust Kubernetes auditing on kube-apiserver - volumes and volumeMounts
  patch: src=etc_kubernetes_manifests_kube-apiserver.yaml.patch dest=/etc/kubernetes/manifests/kube-apiserver.yaml
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: adjust Kubernetes auditing on kube-apiserver - apiserver arguments
  replace: path=/etc/kubernetes/manifests/kube-apiserver.yaml
           regexp=/etc/kubernetes/pki/audit-policy.yaml
           replace=/etc/kubernetes/audit-policy.yaml
           group=root
           owner=root
           mode=0700
  when: inventory_hostname == groups['kubernetes'][0]
  tags: kubernetes

- name: initialize Kubernetes worker
  command: creates=/etc/kubernetes/kubelet.conf
           kubeadm join --token={{ kubernetes_token }} {{ kubernetes_master_ip }}:{{ kubernetes_apiserver_bind_port }} {{ kubeadm_extra_args }} --discovery-token-ca-cert-hash sha256:{{ discovery_token_ca_cert_hash_cmd.stdout }}
  when: inventory_hostname != groups['kubernetes'][0] and discovery_token_ca_cert_hash_cmd.stdout is defined
  tags: kubernetes

- name: fix permissions on files in /etc/kubernetes
  shell: >-
         chmod 700 /etc/kubernetes &&
         chmod 600 /etc/kubernetes/*.conf /etc/kubernetes/manifests/*.yaml /etc/kubernetes/pki/*.key &&
         chmod 644 /etc/kubernetes/pki/*.crt /etc/kubernetes/pki/*.pub
  ignore_errors: yes
  tags: kubernetes

